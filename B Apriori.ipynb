{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [CPSC 310](https://github.com/GonzagaCPSC310) Data Mining\n",
    "[Gonzaga University](https://www.gonzaga.edu/)\n",
    "\n",
    "[Gina Sprint](http://cs.gonzaga.edu/faculty/sprint/)\n",
    "\n",
    "# Apriori\n",
    "What are our learning objectives for this lesson?\n",
    "* Introduce the apriori algorithm\n",
    "\n",
    "Content used in this lesson is based upon information in the following sources:\n",
    "* Dr. Shawn Bowers' Data Mining notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Market Basket\" Analysis\n",
    "In Market Basket Analysis\n",
    "* Dataset consists of \"transactions\" (one per \"row\")\n",
    "* Each transaction has a set of items (an \"itemset\")\n",
    "\n",
    "Grocery store example ...\n",
    "* T1 {bread, cheese, milk}\n",
    "* T2 {bread, cheese, fish, milk, sugar}\n",
    "* T3 {bread, cheese, milk}\n",
    "\n",
    "Note: T1 and T3 have same itemset\n",
    "\n",
    "* Often itemsets ordered to make calculations easier (example later)\n",
    "* Implication is items in itemset \"go\" together (e.g., purchased in a sale)\n",
    "\n",
    "## Association Rules for Itemsets\n",
    "If left itemset THEN right itemset\n",
    "* E.g., IF {bread, sugar} THEN {cheese, milk}\n",
    "* Implies buying bread and sugar is associated with buying cheese and milk\n",
    "* Again, causality is not implied\n",
    "\n",
    "We'll write the above as $L \\rightarrow R$ (e.g., ${bread, sugar} \\rightarrow {cheese, milk}$)\n",
    "\n",
    "## Support for Itemsets\n",
    "For an itemset S\n",
    "* $support(S) = \\frac{count(S)}{N}$\n",
    "    * where $N$ = total # of transactions\n",
    "    * The $count(S)$ is the number of transactions $T$ where $S \\subseteq T$\n",
    "\n",
    "If $S = L \\cup R$ for $Rule_1$: IF $L$ THEN $R$\n",
    "* $support(S)$ (or similarly, $support(Rule_1)$) is same as before $N_{both}/N_{total}$\n",
    "* Just within subset or equal condition ($\\subseteq$)\n",
    "\n",
    "## Confidence for Itemsets\n",
    "If $S = L \\cup R$ for a rule $Rule_1$: IF $L$ THEN $R$\n",
    "* $confidence(Rule_1) = \\frac{count(L \\cup R)}{count(L)} = \\frac{count(S)}{count(L)}$\n",
    "    * Same as before: $N_{both}/N_{left}$\n",
    "\n",
    "Often, only interested in \"confident\" and \"supported\" rules, i.e., where the confidence is at least $minconf$ (e.g., 80%) and support is at least $minsup$ (e.g., 1%)\n",
    "\n",
    "### Lab Task 1\n",
    "Calculate support and confidence for some rules for the following Example Market Basket Analysis (Fake) data:\n",
    "\n",
    "|transaction |itemset|\n",
    "|-|-|\n",
    "|1 |{b, c, m}|\n",
    "|2 |{b, c, e, m, s}|\n",
    "|3 |{b}|\n",
    "|4 |{c, e, s}|\n",
    "|5 |{c}|\n",
    "|6 |{b, c, s}|\n",
    "|7 |{c, e, s}|\n",
    "|8 |{c, e}|\n",
    "\n",
    "Where:\n",
    "* b = bread\n",
    "* c = cheese\n",
    "* e = eggs\n",
    "* m = milk\n",
    "* s = sugar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Apriori Algorithm\n",
    "Leverages the fact that:\n",
    "* If an itemset is supported, all of its (non-empty) subsets are also supported\n",
    "* Removing an item cannot reduce # of matching transactions\n",
    "* e.g., {c,m} $\\rightarrow$ {b} is supported, and so {c} $\\rightarrow$ {b} is also supported\n",
    "\n",
    "The fact implies the following\n",
    "* Let $L_k$ be the set of supported itemsets with $k$ items\n",
    "* If $L_k$ is empty (not supported), then $L_{k+1}, L_{k+2}, ...$ will be empty too (i.e., these sets will not be supported either either)\n",
    "* ... cant improve support by adding items\n",
    "\n",
    "Basic Apriori Algorithm (\"bottom up\")\n",
    "1. Find $L_1$ (the set of 1-item supported itemsets)\n",
    "2. Generate $L_2$ from $L_1$\n",
    "3. Continue ($L_3$ from $L_2$, $L_4$ from $L_3$, etc.) until $L_k = \\emptyset$\n",
    "4. Generate rules from resulting itemsets\n",
    "\n",
    "Generating $L_k$ from $L_{k−1}$ (Step 2)\n",
    "* Create a \"candidate\" itemset $C_k$ from $L_{k−1}$ ... assumes sorted itemsets\n",
    "    * (i) For each $A \\in L_{k−1}$ and $B \\in L_{k−1} (A \\neq B)$\n",
    "        * (ii)     If $A[0:-1] == B[0:-1]$\n",
    "            * (iii)        Add $A \\cup B$ to $C_k$ **unless**\n",
    "                * (iv)             a $k - 1$ subset of $A \\cup B \\notin L_{k−1}$\n",
    "* Set $L_k$ to supported itemsets in $C_k$\n",
    "\n",
    "Step (ii) implies all but last item in $A$ and $B$ match (for $A$ and $B$ sorted)\n",
    "Step (iv) prunes search space\n",
    "* If a $k - 1$ subset is not in $L_{k-1}$ then $A \\cup B$ must not be supported\n",
    "* This is the essential fact exploited by Apriori\n",
    "* That is, adding an item won't increase support\n",
    "\n",
    "Supported itemsets are $L_{2} \\cup ... \\cup L_k$ where $k$ is the last non-empty set\n",
    "* These are also represented solely by $L_k$ considering each elements subsets\n",
    "\n",
    "### Lab Task 2\n",
    "Find all supported itemsets assuming $minsup$ = 25%\n",
    "* $L_1$ = {b}, {c}, {e}, {m}, {s}\n",
    "* $C_2$ = {b, c}, {b, e}, {b, m}, {b, s}, {c, e}, {c, m}, {c, s}, {e, m}, {e, s}, {m, s}\n",
    "* $L_2$ = {b, c}, {b, m}, {b, s}, {c, e}, {c, m}, {c, s}, {e, s}\n",
    "* $C_3$ = {b, c, m}, {b, c, s}, {c, e, s}\n",
    "* $L_3$ = {b, c, m}, {b, c, s}, {c, e, s}\n",
    "* $C_4$ = $\\emptyset$\n",
    "* $L_4$ = $\\emptyset$\n",
    "\n",
    "### Lab Task 3\n",
    "Write a function to generate all k-1 subsets of a list of size k\n",
    "\n",
    "```python\n",
    "def k_1_subsets(itemset):\n",
    "    result = []\n",
    "    for i in range(len(itemset)):\n",
    "        result.append(itemset[:i] + itemset[i+1:]\n",
    "    return result\n",
    "```\n",
    "-- or --\n",
    "```python\n",
    "def k_1_subsets(itemset):\n",
    "    n = len(itemset)\n",
    "    return [itemset[:i]+itemset[i+1:] for i in range(n)]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Rules from Itemsets\n",
    "Naive (brute force) algorithm\n",
    "* Given itemset $S$, find all RHSs\n",
    "    * Start with 1-item RHS, move to 2-item RHS, etc.\n",
    "    * For each rule, remaining items not in RHS become LHS\n",
    "\n",
    "### Lab Task 3\n",
    "Find all rules for $S = {b, c, m}$ and compute confidence\n",
    "\n",
    "|LHS |RHS |Confidence ($N_{both}/N_{left}$)|\n",
    "|-|-|-|\n",
    "|{c, m}$ \\rightarrow$  |{b} |100% (2/2)|\n",
    "|{b, m}$ \\rightarrow$ |{c} |100% (2/2)|\n",
    "|{b, c}$ \\rightarrow$ |{m} |66% (2/3)|\n",
    "|{m}$ \\rightarrow$ |{b, c} |100% (2/2)|\n",
    "|{c}$ \\rightarrow$ |{b, m} |29% (2/7)|\n",
    "|{b}$ \\rightarrow$ |{c, m} |50% (2/4)|\n",
    "\n",
    "* We find confidence for each\n",
    "* And keep rules satisfying $minconf$ (e.g., at 80%)\n",
    "\n",
    "The Problem with this approach:\n",
    "* For an itemset with $k$ items\n",
    "* There are $2^{k}$ - 2 RHSs! (again, all subsets)\n",
    "    * \"-2\" since we don't count set of all items and empty set (for RHS)\n",
    "* Thus, exponential in the size of itemsets\n",
    "\n",
    "Instead use the following fact:\n",
    "* Moving items from LHS to RHS cannot increase rule confidence\n",
    "    * If $R1 = A \\cup B \\rightarrow C$\n",
    "    * We have $conf(R1) = \\frac{count(A \\cup B \\cup C)}{count(A \\cup B)}$\n",
    "    * If $R2 = A \\rightarrow B \\cup C$ ... move $B$ to RHS\n",
    "    * We have $conf(R2) = \\frac{count(A \\cup B \\cup C)}{count(A)}$\n",
    "    * And always true that $count(A) \\geq count(A \\cup B)$\n",
    "        * Again, adding more items cannot increase # of matching transactions\n",
    "\n",
    "From the example:\n",
    "* {b, c} $\\rightarrow$ {m}... $conf$ = 66% (2/3)\n",
    "* {c} $\\rightarrow$ {b, m}... $conf$ = 29% (2/7)\n",
    "* {b} $\\rightarrow$ {c, m}... $conf$ = 50% (2/4)\n",
    "\n",
    "* Given the first rule, we knew second two would be $\\leq$ 66%\n",
    "* Which is below, e.g., $minconf$ = 80%\n",
    "\n",
    "This means we can \"shortcircuit\" rule generation\n",
    "* If no rules with a RHS of size $k$ are \"confident\"... stop searching for rules\n",
    "    * Since algorithm proceeds $k = 1, k = 2, ...$\n",
    "    * Confident means confidence $\\geq minconf$\n",
    "* Can also record RHSs not to consider\n",
    "    * e.g., any that are a superset of $\\{m\\}$\n",
    "    \n",
    "## Apriori Rule Interestingness Measures\n",
    "* There can still be many rules satisfying $minconf$ and $minsup$\n",
    "* Various metrics for further determining \"interestingness\"\n",
    "\n",
    "### Leverage\n",
    "* The difference between support of $A \\cup B$ and support of $A$ and $B$ if independent\n",
    "$$leverage(A \\rightarrow B) = support(A \\cup B) - support(A) \\times support(B)$$\n",
    "* Interested in \"improvement\" of support\n",
    "    * e.g., if $support(A)$ = 10% and $support(B)$ = 10%, if independent we'd expect them to occur together approximately 1% of the time\n",
    "* Typically set $minleverage$ low, e.g., 0.0001 (improve 1 in every 10,000 transactions)\n",
    "\n",
    "### Lift\n",
    "* Similar to leverage\n",
    "* But instead of difference, measures how many more times $A$ and $B$ occur together (than if independent)\n",
    "$$lift(A \\rightarrow B) = \\frac{support(A \\cup B)}{support(A) \\times support(B)}$$\n",
    "* Lift values greater than 1 are considered \"interesting\"\n",
    "* But with all metrics, you must use common sense!\n",
    "\n",
    "Q: Can we apply Apriori to tabular data?\n",
    "* YES! (assuming categorical or discretized values)\n",
    "* Each row becomes a transaction (itemset) of attribute-value pair items\n",
    "* Itemsets restricted though, e.g., $\\{s = 1, j = 3\\}$ but not $\\{s = 1, s = 2\\}$ for attributes $s$ and $j$.\n",
    "* This affects how itemsets are combined in Apriori"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
